This project uses the BLIP (Bootstrapping Language-Image Pretraining) model to generate captions and extract keywords from video files or URLs. By processing video frames, it creates descriptive captions for each frame and extracts keywords, making it easy to generate metadata for videos.

The tool allows users to upload videos or provide a video URL. It processes the video frame by frame, generates captions using BLIP, and extracts keywords from the captions. The results are displayed as unique captions and a list of relevant keywords, providing valuable insights into the video's content.

Built with Gradio, the application offers a simple and user-friendly interface, making it easy for anyone to use, without requiring advanced technical knowledge. This tool is ideal for automating video content analysis, enhancing searchability, and improving the categorization of video resources.

Key Features:

Upload video or provide a URL

Frame-by-frame video processing

Captions generated using the BLIP model

Keyword extraction from captions

Easy-to-use Gradio interface for deployment
